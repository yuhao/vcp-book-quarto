# Welcome {.unnumbered}

This book attempts to present a unified view of visual computing, looking at it as a series of signal transductions across different domains --- optical, analog, digital, and semantic --- along with the processing that happens within each. Any sufficiently complex visual computing system worth studying will likely involve both transductions and processing in all of these domains.

Take Augmented Reality glasses as an example.
The input signals --- light --- are in the optical domain. These first need to be converted into electrical signals by an image sensor so that a computer system can process them to extract semantic information--say, the orientation of a table in a room. The system then simulates light transport to generate photorealistic, context-appropriate virtual objects--perhaps a mug correctly oriented on that very table. Finally, these virtual objects must be transformed back from electrical signals, in the form of pixels, into optical signals by the display.

But wait, we are still not done!
The light emitted by the display enters our eyes, where photoreceptors in the retina convert the optical signals back into electrical ones. The retina and, further downstream, the brain, process these signals, eventually giving rise to our perception and cognition: we see a virtual mug sitting naturally on a real table.

With this perspective in mind, the main motivation for writing the book grew out of a simple observation: we must jointly design and optimize an end-to-end visual computing system *holistically*.