# How Do Photoreceptors Work {#sec-chpt-hvs-receptor}

## Counting Photons: Principle of Univariance {#sec-chpt-hvs-receptor-counting}

![Anatomical structures of rods and cones. The outer segment contains photon-absorbing photopigments, which of which has the capability of absorbing a photon and being excited/isomerized after absorption. From @wandell1995foundations[Fig. 3.2].](figs/photoreceptors){#fig-photoreceptors width="80%"}

Anatomically, a photoreceptor has two parts: an inner segment and an outer segment.
Photons enter from the inner segment, which for the most part can be thought of as a waveguide that funnels the photons to the outer segment.
The outer segment contains the photon-absorbing pigments.
This is illustrated in @fig-photoreceptors.

Conceptually, we can think of each photoreceptor as a bucket that collects photons.
There are millions of buckets sitting on the retina, taking a shower of photons.
Many photons entering the eye will not hit any bucket: they are absorbed before they reach the bucket (e.g., by the lens).
Any photon that does hit the bucket has a certain *probability* of being absorbed.
The absorption probability varies with the photoreceptor type and the photon's wavelength.

Fundamentally, a photoreceptor can absorb photons because it contains light-sensitive, photon-absorbing pigments, each of which is able to absorb one photon.
Each rod photoreceptor has tens of millions of such pigments [@milo2015cell, pp. 142-147; @nathans1992rhodopsin].
Why is a photon's absorption probability not 100\% once it enters a photoreceptor?
For one, a photon might not meet a photopigment as it travels through the photoreceptor before the exit.
Even if a photon hits a pigment, its absorption is still probabilistic, as absorption is dictated fundamentally by quantum mechanics.

Once a photon is absorbed, it has a certain probability of "exciting" or "isomerizing" the pigment.
A pigment **excitation** or **isomerization** generates a certain level of electrical signal --- in the form of a current or voltage change across the cell membrane of the photoreceptor.
The excitation probability once a photon is absorbed is called the **quantum efficiency** of the pigment.
Quantum efficiency is about two-thirds in the visible spectrum and is not wavelength sensitive [@dartnall1972photo; @kropf1982photo; @fu2010phototransduction].
A pigment excitation is also called pigment **bleach**, since the pigment after excitation is no longer responsive to light as if it is bleached.

The process of initiating an electrical response upon a photon absorption is called phototransduction.
We will study this process in detail shortly in @sec-hvs-receptor-cascade.
For now, it is important to know that for a given photoreceptor class, the electrical response caused by a photon absorption is constant regardless of the photon's wavelength.
This is called the **Principle of Univariance** [@rushton1972visual; @rushton1972review; @naka1966s]: each photon that generates an electrical response has the same effect as any other photon that does so.
In other words, the only effect that wavelength has is to impact the probability a photon gets absorbed; after absorption, the wavelength information is lost.

A crucial implication of this principle is that any two lights that are equally absorbed/excited will be seen as the same light by the human vision.
For the purpose of comparing two lights, we can think of each bucket as having a counter; every time a photon is absorbed and excites a pigment, the counter gets incremented by 1.
If two lights lead to the same counter value, they are perceptually the same.
Crucially, if a bucket's counter is, say, twice as high as another's, it does *not* mean the electrical responses produced by the first photoreceptor are twice as high as that of the second.
We will see why this is the case shortly.

## Spectral Absorbance, Absorptance, and Sensitivity {#sec-chpt-hvs-receptor-absorb}

To understand vision in everyday scenarios, what we care about is not the probability of how a single photon is absorbed and excites a pigment, but the collective behavior of a flux of photons that enter our eyes.
Conveniently, when we have a large population of photons, the probability that an individual photon causes an excitation translates to the *percentage* of incident photons that are absorbed and/or cause excitations.
In fact, the percentage of absorption is the quantity that we can directly measure.

There are in general two ways to estimate the absorption rate of a flux of photons.
The direct way of measurement is using a technique called microspectrophotometry (MSP).
The indirect method is to measure the electrical responses using, e.g., a suction electrode, and then estimate the absorption.
The indirect method gives us only relative absorption across wavelengths, while the MSP approach gives us absolute absorption.

### Absorbance Spectra from Microspectrophotometry {#sec-chpt-hvs-receptor-absorb-msp}

The idea of MSP is to shine a beam of light through a photoreceptor and then measure, at the other side, the percentage of photons that are transmitted, i.e., unabsorbed [@bowmaker1984microspectrophotometry].
Ignoring back-scattering ^[Without back-scattering, we can assume any unabsorbed photons will be transmitted through, and measured at the other side of, the photoreceptor. In reality, a very small amount of some photons might be scattered backward toward where they come from and will not be measured either, but the effect is small.], photon absorption by photopigments in a photoreceptor can be modeled using the Beer-Lambert law.
The **transmittance** at wavelength $\lambda$ is defined as the ratio between the amount of transmitted photons $I_d(\lambda)$ and the amount of total incident photons $I_0(\lambda)$:

\begin{align}
    T(\lambda) = \frac{I_d(\lambda)}{I_0(\lambda)} = e^{-\epsilon(\lambda) c l},
\end{align}

where $\epsilon(\lambda)$ is called the absorption coefficient and is wavelength dependent, $c$ is the concentration (the number of pigments per unit volume), and $l$ is the optical length, the length through which a photon has to travel\footnote{$\epsilon(\lambda)$ so-defined has a unit of $m^2$, and $c$ so-defined has a unit of $1/m^3$. In the literature, sometimes people define $\epsilon(\lambda)$ to be the **molar absorption coefficient**, which has a unit of $m^2/mol$, and define $c$ to be the **molar concentration** (the number of moles of pigments per unit volume), which has a unit of $mol/m^3$.}.
Both $c$ and $l$ are inherent properties of a photoreceptor and are not dependent on photon wavelength.

**Absorptance** $a(\lambda)$, the percentage of absorption at $\lambda$, is naturally $1-T(\lambda)$.
**Absorbance** $A(\lambda)$ (also called the **optical density**), whose spelling is subtly and annoyingly different from that of absorptance, is defined as:

$$
    A(\lambda) = -\ln(T(\lambda)) = \epsilon(\lambda) c l.
$$ {#eq-absorbance}

Therefore, absorptance $a(\lambda)$ and absorbance $A(\lambda)$ are related by:

$$
    a(\lambda) = 1 - e^{-A(\lambda)}.
$$ {#eq-absorptance}

![Left: Log-scaled spectral sensitivities of the cones (L, M, S) in a macaque measured using the suction electrode method; adapted from @baylor1987spectral[Fig. 3A]. Right: Absorbance spectra of the three cones (L, M, S) and the rod (R) in a human, measured using MSP; adapted from @dartnall1983human[Fig. 2]. The spectra in both cases are normalized to peak at 1/100.](figs/receptor_sensitivity){#fig-receptor_sensitivity_2 width="100%"}

We would repeat this experiment over a frequency range and obtain the axial absorbance at each sampled frequency.
The resulting plot is usually called the **absorbance spectrum**.
One such example is shown in the right panel in @fig-receptor_sensitivity_2, measured by @dartnall1983human on humans.
Much such data has been obtained in the literature, the earliest of which is perhaps by George Wald and his colleagues [@marks1964visual; @brown1964visual] who identified three distinct absorbance spectra in cone-mediated vision and, thus, provided direct physiological evidence for the existence of three classes of cones.
The three cone types are generally referred to as the **L**, **M**, and **S** cones, since their absorbances peak at, relatively, long, medium, and short wavelengths.

Decades before the work by Wald et al., Ragnar Granit measured the spectral sensitivities of the retinal ganglion cells [@granit1941retinal; @granit1943physiological; @granit1945electrophysiological; @granit1945colour] ^[Granit shared the Nobel Prize in 1967 with George Wald and Haldan Keffer Hartlin largely due to this work.].
Granit showed the existence of two classes of RGCs: 1) one that has a broader spectral sensitivity whose peak shifts to shorter wavelengths from photopic vision to scotopic vision, and 2) one whose spectral sensitivities are narrower and fall generally into three main groups.
The former is the physiological version of the Purkinje shift that we will discuss in @sec-chpt-hvs-color-oppo-light, and provides direct evidence for the convergence of the rod and the cone vision pathways (@sec-chpt-hvs-percept-retina-rodcone-pathways and @fig-retinal_nn).
The latter is the first direct evidence of the existence of three dinstinct wavelength encoding mechanisms (albeit not at the photoreceptor level), essential for the trichromatic color vision.
<!-- %see dowling1967nobel and granit1968development (nobel lecture) too.
%granit1945electrophysiological is a summary of his own work. Sec. 5 is quite interesting (based on work in granit1945colour), as it shows a mechanism to isolate the spectra of his modulators. originally he by chance could find RGCs that have narrow spectra (modulators), but he wanted to have a more scalable way to get modulator spectra and test the hypothesis that denominators are formed by modulators. in modern terms, his modulators are definitely not just single cones, but the technique in Sec. 5 is interesting: adapting colored lights would universally reduce the sensitivity of rod's LEF and any discrependacy must be because of cones (or the resulting modulators) whose sensitivities are not suppressed by the adapting light, so they can they derive the modulator spectra.
% in this scheme, blue modulators could give non-zero M curves under R and G adapting light, and R modulators could give such spectra under B/G adapting lights, and so on. Fig. 9 averages all the modulator spectra by adapting light, and Fig. 10 averages modulator spectra by modulator type (based on the pre-established preferential peak of each type).
% his view is perhaps incorrect in modern terms. Fig. 10 in granit1945colour shows his guess of the "fundamental sensation curves", which are cone fundamentals.  he later then says "fundamental sensation curves cannot be shown to exist" and "They are theoretical postulates which can merely be satisfied by adding modulators within the three preferential regions".  he shows in fig. 10 the R fundamental curve is the sum of M_y and M_r modulators.
% basically, since he observed more than 3 modulators, "On the basis of the known modulators it would be necessary to develop a 6- or 7-colour theory, based on one red and one yellow modulator, two or three green modulators and two blue ones", he concludes that each cone fundamental must be sumed from individual modulators. in modern terms, we have only three cone classes, but they converge/combine in different ways at the RGCs, which is what he measured. -->


#### Normalization

Quite often, the absorbance spectrum is normalized to peak at unity, as is the case in @fig-receptor_sensitivity_2 (right).
According to @eq-absorbance, normalizing absorbance across different wavelengths is equivalent to normalizing $\epsilon$ across wavelengths, since $c$ and $l$ are not wavelength specific, whereas $\epsilon$ is.
$c$ and $l$ might vary across species and across individuals and might differ between different illumination methods (see below), but $\epsilon$, which is fundamental to the photopigment, does not.
Therefore, the normalized absorbance spectrum tells us something fundamental about the wavelength sensitivity of the photopigments.

Perhaps a subtlety but quite confusing when perusing the literature, the maximum absolute absorbance across all wavelengths (i.e., the peak of an absorbance spectrum) is usually simply called the optical density; "peak optical density" would have been more accurate, as optical density is wavelength specific.
Using the peak optical density and the normalized absorbance spectrum, we can reconstruct the absolute absorbance spectrum; from there we can get the absolute absorptance spectrum.

While not shown here, the peak absorbance between rods and cones is not that different.
The peak absorbance of rods is about 0.475, and the value is about 0.375 for foveal S cones and 0.525 for foveal L/M cones [@bowmaker1978visual; @bowmaker1980visual].
The large sensitivity difference between rod vision and cone vision is not primarily attributed to the difference in their ability to absorb photons.
<!-- %http://www.cvrl.org/database/text/optdens/optdens.htm -->

#### Correcting for Transverse Illuminations

There is one more complication.
With MSP, we illuminate a photoreceptor *transversely*, i.e., the light passes from one side of the photoreceptor to the other side.
In reality, when a photon enters a photoreceptor, it travels *axially* from the inner segment through the outer segment.
The main difference between these two scenarios is the optical length that a photon has to travel.
A photoreceptor is tall and skinny, so its width is much smaller than its length, about 2.5 $\mu m$ wide and 35 $\mu m$ long for a fovea L/M cone [@polyak1941retina].
<!-- %http://www.cvrl.org/database/text/outseg/length.htm
%bowmaker1980visual cites polyak 1941 "25 um for parafoveal S cone"
%bowmaker1980microspectrophotometric cites polyak 1941 "35 um for foveal cones and 25 um for extra-foveal rods," -->

Therefore, we need to first calculate the absorbance per unit length, called the **specific absorbance**, and then scale the specific absorbance by the axial length of the photoreceptor to obtain the axial absorbance, from which we can estimate the axial absorptance using @eq-absorbance.
This is shown below (omitting $\lambda$ for simplicity):

$$
\begin{align}
    A_{\text{transverse}} &= -\ln(p_{\text{transverse}}) = \epsilon c l_{\text{transverse}} \\
    A_{\text{specific}} &= \frac{A_{\text{transverse}}}{l_{\text{transverse}}} = \epsilon c \\
    A_{\text{axial}} &= A_{\text{specific}} l_{\text{axial}} \\
    T_{\text{axial}} &= e^{-A_{\text{axial}}}
\end{align}
$$ {#eq-axial}

### Relative Absorptance Spectra from Electrical Responses {#sec-chpt-hvs-receptor-suction}

Another method is by measuring the photoreceptor's electrical responses across different wavelengths using techniques such as suction electrode, which records the electrical responses of an isolated photoreceptor sucked into a micropipette.
Spectra so estimated are usually called the spectral sensitivity of the photoreceptors in the literature, but as we will see, they are equivalent to the *normalized* absorptance spectra.

![Each curve shows the electrical response (in photovoltage; $y$-axis) as a function of light intensity ($x$-axis) at a given wavelength. To estimate the relative sensitivity/absorptance between two wavelengths, we laterally shift one curve so that it coincides with the other. Given the Principle of Univariance, the amount of shift is proportional to the relative absorptance. From @baylor1973detection[Fig. 8].](figs/spectral_sensitivity_from_photocurrents){#fig-spectral_sensitivity_from_photocurrents width="80%"}

@fig-spectral_sensitivity_from_photocurrents illustrates the idea, where @baylor1973detection measured the peak electrical response of a turtle cone (in photovoltage; $y$-axis) as a function of light intensity ($x$-axis) at two wavelengths: 644 $nm$ and 539 $nm$.
We see that the curves are almost parallel to each other: we can laterally move the 644 $nm$ curve to coincide with that of 539 $nm$.
In this case, we have to shift the former by 1.27 log units.

Think for a second what this means.
When we increase the intensity at 644 $nm$ by a factor of $10^{1.27}$, the sheer number of photons absorbed at 644 nm is increased by a factor of $10^{1.27}$, too.
That means without scaling the number of incident photons at 644 $nm$ is $10^{-1.27}$ (about 5.4\%) of that at 539 $nm$.
Even with just 5.4\% of incident photons, 644 $nm$ light is able to produce the same level of electrical response, i.e., cause the same amount of photon absorption (given the Principle of Univariance), as the light at 539 $nm$.
Therefore, we can say the absorption rate (absorptance) at 644 $nm$ is $10^{1.27}$ higher than of that at 539 $nm$.

We repeat this experiment across other wavelengths and obtain the relative spectral sensitivity/absorptance spectra.
The left panel in @fig-receptor_sensitivity_2 shows one such example obtained by @baylor1987spectral on macaque cones.
Critically, the absorptance so obtained is relative: we do not know the absolute absorptance at either wavelength.
The $y$-axis is necessarily normalized to peak at unity.
Similar data have been collected on humans as well [@schnapf1987spectral; @kraft1993visual].

#### Normalized Spectra From the Two Methods Match Well

It is worth noting that the suction electrode method also uses transversely illuminated lights.
Since the absorptance obtained here is relative, we cannot easily use the method in \Eqn{eq:axial} to obtain the absorptance spectra for the axial illumination.

Here is the catch.
Numerically, $1 - e^{-A} \approx A$ when $A$ is small.
When we illuminate a photoreceptor transversely, the optical length $l$ is the photoreceptor width, which is short, which means $A$ is small [@wyszecki1982color, pp. 588, 594].
Therefore, the transverse absorbance and transverse absorptance are approximately equal.
So the normalized absorptance spectrum given by the suction electrode method *is* approximately the normalized absorbance spectrum, as is shown experimentally [@schnapf1987spectral; @stockman2000spectral, Fig. 11].

The normalized absorbance spectra are still not sufficient, since to use the method in @eq-axial we need to know the absolute absorbance spectra.
People usually have to resort to another data source that provides absolute peak absorbance or fit the data against, e.g., psychophysical measurements that provide some form of absolute measures [@kraft1993visual; @baylor1984photocurrent; @baylor1987spectral].

## Cone Fundamentals: Cornea-Referred Spectral Sensitivities {#sec-chpt-hvs-receptor-fundamentals}

Our discussions so far have focused on absorption by the photoreceptors, but for a flux of photons arriving at the cornea about to enter our eye, they are also absorbed even before reaching the photoreceptors.
Accounting for these \textbf{pre-receptoral} filters is important to model human vision.
Spectral sensitivities that account for these pre-receptoral filters are what we call the \textit{cornea-referred} spectral sensitivities.

### Cone Fundamentals From Physiology

There are two such pre-receptoral filters: the ocular media (@sec-chpt-hvs-percept-absorb) and the macular pigments, which are located at a small area in the fovea.
Macular pigments absorb light presumably to counter some of the aberrations from the ocular media and to protect the retina from light damage [@snodderly1984macular].
Both ocular media and macular pigments absorb light selectively over the spectrum, just like photoreceptors do.

We can model $E(\lambda)$, the fraction of photons arriving at the cornea that are absorbed by the photoreceptors:

\begin{align}
    E(\lambda) = l(\lambda) m(\lambda) a(\lambda)
\end{align}

\noindent where $a(\lambda)$ represents the photoreceptor absorptance spectrum, $l(\lambda)$ and $m(\lambda)$ represent ocular and macular transmittance spectrum, respectively, i.e., the fraction of photons at $\lambda$ *unabsorbed* by the ocular media (e.g., lens) [@boettner1962transmission; @norren1974spectral] and the macular pigments.
@fig-cone_fundamentals illustrates this process.

![Cornea-referred spectral sensitivity function measures the percentage of photons arriving at the cornea (about to enter the eye) that are absorbed by each photoreceptor type at each wavelength. The cone versions of this are called the cone fundamentals and are visualized in the bottom right. The sensitivity metric relates to the rate of pigment excitation only by a constant scaling factor (i.e., the photoreceptor quantum efficiency, which is about two-thirds). It is a product of ocular transmittance (top left), macular transmittance (top right), and photoreceptor absorptance (bottom left). The macular transmittance and lens transmittance are from @stockman1999spectral; the cone absorptance spectra are estimated from @stockman2000spectral (different from the @dartnall1983human data used in @fig-receptor_sensitivity; see the methodology in @absorption_spectra_cvrl).](figs/cone_fundamentals_new){#fig-cone_fundamentals width="100%"}

<!-- %the probability a here is a constant; one might think that absorption becomes harder as a photon travels through the cell, but we are calculating the total absorption *given* a cell length. so the probability here already considers the cell length. See https://web.stanford.edu/~wandell/data/papers/2022_ISETBio_VisualEncoding.pdf#page=19.65
% what this means is that the amount of excitation (and absorption) is proportional to light power. so if we want to increase absorption we linearly increase power. this however does not mean response is linearly wrt power/excitation/absorption; in fact we know that r/rmax is not linear. so what the spectral sensitivity function really means the not the response per unit power but the amount of excitation per unit power. -->

We call $E(\lambda)$ the cornea-referred spectral sensitivity function, since it is calculated with respect to the incident lights at the cornea surface.
When $a(\lambda)$ is replaced by the absorptance spectra of the three classes of cones, the resulting sensitivity functions are more commonly referred to as the **cone fundamentals**.

We can make a few general observations about the cone fundamentals.
First, the cone sensitivity drops to 0 beyond the 380 nm and 780 nm range, a range we usually call the visible spectrum, since there will be no pigment excitation beyond that range: lights beyond that range are invisible.
Second, S cones are generally the least sensitive of the three cone types, but it is not because of the photoreceptors but because of the pre-receptoral filters, which absorb mostly low-wavelength lights.
Finally, the sensitivity peaks of the L cones and M cones are very similar (off by about 20 $nm$), but both are rather far from the peak of the S cones.
We have discussed the reason behind this when discussing @fig-receptor_sensitivity.

### Cone Fundamentals From Psychophysics

The spectral sensitivities discussed above are measured physiologically.
We can also measure such functions through psychophysics using the increment-threshold method.
A typical set up is one where there is a uniform background illumination and a spot light superimposed at the center of the background.
We ask a participant to adjust a knob to control the intensity of the spot light so that it is just noticeable from the background.
The sensitivity is then defined as the reciprocal of the threshold intensity.
We repeat this experiment for each sampled wavelength across the spectrum to obtain a sensitivity curve.
This method is first used in the pioneering work done by W.S. Stiles [@stiles1939directional; @stiles1959color; @stiles1964appendix], and is adopted in virtually all later work [@wald1964receptors; @smith1975spectral; @stockman1999spectral; @stockman2000spectral].

A curious question is how we can separate the sensitivity of different photoreceptor types, given that the spectral sensitivities of the four photoreceptor types overlap.
There are two methods to isolate rods from cones.
We can either use very dim lights, to which cone responses are too small to contribute to vision [@crawford1949scotopic], or we could measure from people with rod monochromacy --- individuals who have only rods.
When measuring cone sensitivities, we will use intense lights that almost completely saturate rods.

Isolating the three cone types from each other is generally challenging with individuals with normal vision.
W.S. Stiles' initial work [@stiles1939directional; @stiles1959color] designed special conditions of background illumination to suppress the sensitivity of two unwanted cone types while sparing the one under study.
Modern studies usually turn to color-deficient individuals who lack one or two cone types.
Isolating S cones is done by measuring from S-cone monochromats [@stockman1999spectral].
Isolating L and M cones is challenging because individuals with only L or M cones are very rare and the spectral sensitivities of the L and M cones overlap substantially.
Instead, a common approach is to resort to Protanopes and Deuteranopes; the former has only M and S cones, and the latter has only L and S cones.
To isolate M (L) cones from the S cones, we measure from Protanopes (Deuteranopes) using lights that have high spatial and/or temporal frequencies, to which S cones are known to be insensitive [@stockman2000spectral; @smith1975spectral].

### Physiological and Psychophysical Sensitivities Match Well

We can then compare the spectral sensitivity data from physiology and from psychophysics.
This is shown in @fig-spectral_sensitivity_comparison.
See the figure caption for details.
Overall it is fair to say that the two sets of data match well.

![Left: comparison of the physiologically-obtained rod spectral sensitivity from macaques (open circles) and the rod spectral sensitivity from human psychophysics (filled circles); adapted from @baylor1987photoreceptor[Fig. 14], which is after @baylor1984photocurrent[Fig. 5]. Right: comparison of the spectral sensitivity of the three cone types between physiology data (open circles; from macaques) and psychophysics data (curves; from humans); adapted from @baylor1987spectral[Fig. 5]. The human psychophysics data is from @stiles1959color for cones and from @crawford1949scotopic for rods.](figs/spectral_sensitivity_comparison){#fig-spectral_sensitivity_comparison width="100%"}

Think about what this comparison means.
What we measure in psychophysics is the threshold intensity (at each wavelength) needed to evoke a criterion level of human *behavioral response* (i.e., just noticeability).
The threshold intensity in the physiological measurement represents how much light is needed (at each wavelength) to cause the same amount of pigment absorption and, by the Principle of Univariance, the amount of *electrical responses*.
The fact that the two sets of data match suggests that the amount of electrical response we need to evoke a just-noticeable level of perception is a constant regardless of wavelength, a perhaps unsurprising inference.

Interestingly, the physiological data in \Fig{fig:spectral_sensitivity_comparison} is obtained from macaques, and the psychophysical data is from humans.
The fact that they match well suggests the similarities of the visual system among primates --- we have come a long way since the monkey days, but our photoreceptors have not changed much.
Other studies obtaining the physiological sensitivity data from humans show similarly good matches with human psychophysical data [@crescitelli1953human; @kraft1993visual; @bowmaker1980visual; @mollon1982colour].

## Beyond Counting Photons: Phototransduction and Recovery {#sec-hvs-receptor-cascade}

The discussion so far about (spectral) sensitivity has focused on the ability of different types of photoreceptors to absorb ("count") photons at different wavelengths, and by that measure, rods and cones are not that different: their peak absorbances differ by less than 10\% (@sec-chpt-hvs-receptor-absorb-msp).
So then why do we say rod vision is more sensitive than cone vision?
What we have ignored is the absolute *strength* of the electrical response once photons are absorbed.
To understand the absolute response strength, we need to understand the cellular and molecular processes underlying how electrical responses are actually produced from pigment excitations.
These processes constitute the so-called **phototransduction cascade** and are the focus of this section.
George Wald is largely credited for elucidating these processes [@wald1933vitamin; @wald1968molecular].
