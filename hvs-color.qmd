# Color Vision {#sec-chpt-hvs-color}

This chapter studies color vision.
We will review two main retinal stages responsible for color vision: wavelength encoding by the photoreceptors and the opponent processes that take place post-receptorally.
We discuss both the behavioral phenomena as well as the potential neural and physiological basis.
That this chapter almost exclusively focuses on the retinal mechanisms should in no way be taken to imply that cortical mechanisms are insignificant to color vision.
We take this approach because: 1) the retinal mechanisms are much better understood and 2) many real-world applications such as color reproduction and detecting colored patterns could be adequately modeled by retinal mechanisms.

## Color Encoding at Photoreceptors {#sec-chpt-hvs-color-receptor}

Newton presumably did the famous experiment where he showed that a beam of white light is really a mixture of photons at different wavelengths, and each wavelength gives a different color percept.
Color is very much our subjective sensation.
What is the physical reality is the spectral power distribution of light.
In Newton's words: "*rays of Light in falling upon the bottom of the eye excite vibrations in the retina. Which vibrations, being propagated along the solid fibres of the optick Nerves into the Brain, cause the sense of seeing.*" [@newton1952opticks].

### From Light Spectrum to Cone Responses {#sec-chpt-hvs-color-receptor-cones}

As we have seen before, there are three classes of cones, each with a different spectral sensitivity function or a cone fundamental.
We will now see how the cone fundamentals encode wavelength information that eventually gives rise to color vision.

The cone fundamentals we have seen in @fig-cone_fundamentals tell us the absolute spectral sensitivities of photoreceptors.
It is customary to normalize the cone fundamentals to peak at unity.
This normalization eliminates the differences at peak across photoreceptor types, but retains the relative spectral sensitivity within a particular type.
Thus, this normalization is useful when we care only about comparing the sensitivity of different wavelengths of a particular type of photoreceptor, but not across different types of photoreceptor.

In addition, the cone fundamentals in @fig-cone_fundamentals are defined on an "equal-quantal" basis: the sensitivities at different wavelengths are given assuming each wavelength has the same amount of photons.
Sometimes, especially in CIE standards, the cone fundamentals (and other functions related to cone fundamentals, such as luminous efficiency function and color matching functions, both of which we will discuss later) are defined based on "equal-energy", assuming each wavelength has the same energy/power, not the same amount of photons.
As we will see shortly, the equal-energy definition is practically useful since the spectrum of a light is defined as power/energy distribution, rather than quantal distribution, over wavelength.

![Physiological measurements give us absolute spectral sensitivities on an equal-quantal basis (left), but in color science each cone fundamental function is usually normalized to peak at unity and then converted to an equal-energy form (right).](figs/normalized_cone_fundamentals_new){#fig-normalized_cone_fundamentals width="80%"}

@fig-normalized_cone_fundamentals compares the absolute, equal-quantal cone fundamentals with the normalized, equal-energy cone fundamentals.
A normalized, equal-energy sensitivity function tells us the relative amount of photon absorption given a unit power at each wavelength.
For instance, the normalized L cone response is 1 at 570 nm and 0.4 at 630 nm.
This means that given two lights that have the same power/energy, one with photons only at 570 nm and the other with photons only at 630 nm, the fraction of photons absorbed in the 630 nm light is about 40\% of that in the 570 nm light.

Critically, this also means if we have a 570 nm light at 1 W and a 630 nm light at 2.5 W, the two lights would cause the same amount of pigment excitations in L cones.
If we had only L cones, these two lights would be seen as the exact same light, because the HVS will receive the exact amount of electrical responses --- according to the Principle of Univariance.
This explains why we could not see colors at night, when only rods are functioning.

In reality, of course, most humans have three classes of cones, so what *is* the signal we receive?
Given the Spectral Power Distribution (SPD) of a light $\Phi(\lambda)$, we can calculate the total number of photon absorptions for each cone type, given by:

$$
\begin{align}
  L &= \int_\lambda L(\lambda) \Phi(\lambda) d\lambda \\
  M &= \int_\lambda M(\lambda) \Phi(\lambda) d\lambda \\
  S &= \int_\lambda S(\lambda) \Phi(\lambda) d\lambda
\end{align}
$$ {#eq-spd2cones_int}

where $L(\lambda)$, $M(\lambda)$ and $S(\lambda)$ represent the cone sensitivity functions.
The fact that we can directly multiply $\Phi(\lambda)$ with, say, $L(\lambda)$ is a result of defining $L(\lambda)$ on an equal-energy/power basis.
The L/M/S values we calculate represent the total number of photon absorptions given an incident light.
You would know why we care about photon absorption: it is equivalent to pigment excitation up to a constant scaling factor, and pigment excitations produce electrical signals that our brain actually receives.
We sometimes simply call the L/M/S value the **cone responses** or **tristimulus values** of a light, but you should know that they do not represent the actual magnitude of the electrical responses of the cones, since the magnitude is not linearly proportional to absorption as we have discussed before.

In actual computation we discretize the spectra and perform summation rather than integration.
We also limit the summation to within the [380 nm, 780 nm] range, since the cone fundamentals are practically 0 beyond that range.
Assuming that we are quantizing the spectra at a 1-nm interval, the cone responses are linearly related to the light spectrum by:

$$
\begin{align}
\begin{bmatrix}
L(380), L(381), \cdots, L(780)\\
M(380), M(381), \cdots, M(780)\\
S(380), S(381), \cdots, S(780)\\
\end{bmatrix}
\times
\begin{bmatrix}
\Phi(380)\\
\Phi(381)\\
\vdots \\
\Phi(780)\\
\end{bmatrix}
=
\begin{bmatrix}
L\\
M\\
S\\
\end{bmatrix}
\end{align}
$$ {#eq-spd2cones}

We can see that this is a huge dimensionality reduction.
That is, our brain receives only the three-dimensional cone responses, not the actual spectrum of the light, which is of a much higher dimension.
This is the basis of the **trichromatic theory** of color vision: color is a three-dimensional system.
The theory was first proposed by @young1802ii, who conjectured that there are three types of receptors, and later rediscovered, popularized, and extended by Hermann von Helmholtz in the later part of the nineteenth century.

The huge dimensionality reduction also means there are infinitely many lights (with different SPDs) that will be seen as having the same color, as long as they cause the same cone responses.
One way to understand this is if we try to solve the system of linear equations in @eq-spd2cones given $[L, M, S]^T$, with the constraint that the $\Phi$ vector must be non-negative everywhere (since power cannot be negative),
we would generally end up with infinitely many solutions, since it is an *under-determined* system.
The fact that multiple physically different lights can end up having the same color is called **metamerism**, and these lights are called **metamers** of each other.

### Cone Excitation Space, Spectral Locus, and HVS Gamut {#sec-chpt-hvs-color-receptor-conespace}

![Spectral locus in LMS cone space; from the interactive tutorial in @zhu2022cone2cmf.](figs/spectral_locus_lms){#fig-spectral_locus_lms width="100%"}

The cone fundamentals essentially give us a color space, which we call the **LMS cone space** or **cone excitation space**.
A color space allows us to geometrically interpret a color as a point in the coordinate system.
In the cone space, the color of a light is interpreted as the amount of responses in each of the three cone classes produced by the light (as calculated by @eq-spd2cones).

The **spectral locus** is a curve on which each point represents the color of a spectral light at a wavelength.
@fig-spectral_locus_lms shows the spectral locus in the LMS cone space on the right and the cone fundamentals on the left.
The L, M, and S cone responses of a spectral light at, for instance, 605 nm are 0.775, 0.265, and 0, which corresponds to the point [0.775, 0.265, 0] in the cone space.
Connecting these points for all the spectral lights gets us the spectral locus in the LMS space.

We know a color corresponds to a point in the cone space, but does an arbitrary point in the cone space correspond to a real color?
*No*.
For instance, if a point has a negative coordinate it obviously could not be a color of a real light, since that a negative cone response would require negative power in the light.
Also, [1, 0, 0] is also not a real color, since there is no real light that can produce only L cone response but no responses from M and S cones --- if you examine the cone fundamentals carefully.
We call these colors **imaginary colors**, since they cannot be produced by physically realizable lights, where the power must be non-negative at any wavelength.

In principle, an [L, M, S] point corresponds to a real color if @eq-spd2cones has a non-negative solution for $\Phi$.
The total set of [L, M, S] points that have a non-negative $\Phi$ solution corresponds to all the colors that humans can see, which is called the **gamut** of the human visual system.
Geometrically, if a point in the cone space cannot be constructed through a *positive*, linear combination of the points on the spectral locus, it then is not a real color, since the SPD of a real light must be a positive, linear combination of the SPDs of the spectral lights.

For instance, the line segment connecting two points on the spectral locus contains real colors that can be produced by mixing some amount (i.e., positive linear combinations) of the two spectral lights.
Of course we can apply this iteratively: once you get a real color through combining spectral colors, the color itself can then be used as a basic color to create other colors.
@zhu2022gamut is an interactive tutorial that visualizes the HVS gamut in the cone space (and others), which you are invited to go through.

## Trichromatic Color Matching {#sec-chpt-hvs-color-cme-lin}

We can produce, in theory, any color by mixing three other colors, which we call the **primary colors**.
Here is the mathematical intuition.
Let's say the SPDs of the three primary lights are $R(\lambda)$, $G(\lambda)$, $B(\lambda)$.
What is the power of each of the primary lights we need to produce the color of a target light $\Phi(\lambda)$?
For the color of the mixed light to match that of the target light, their corresponding cone responses must match:

$$
\begin{align}
\begin{bmatrix}
\sum R(\lambda)L(\lambda),~ \sum G(\lambda)L(\lambda),~ \sum B(\lambda)L(\lambda)\\
\sum R(\lambda)M(\lambda),~ \sum G(\lambda)M(\lambda),~ \sum B(\lambda)M(\lambda)\\
\sum R(\lambda)S(\lambda),~ \sum G(\lambda)S(\lambda),~ \sum B(\lambda)S(\lambda)\\
\end{bmatrix}
\times
\begin{bmatrix}
r\\
g\\
b \\
\end{bmatrix}
=
\begin{bmatrix}
\sum\Phi(\lambda)L(\lambda)\\
\sum\Phi(\lambda)M(\lambda)\\
\sum\Phi(\lambda)S(\lambda)\\
\end{bmatrix},
\end{align}
$$ {#eq-cme}

where $r, g, b$ represent the power of the three primary lights, respectively.
This system in general has one unique solution because we have the same number of unknowns ($r, g, b$) as the number of equations.
Each of the three equations constrains the cone-response matching of one class of cones.
This means there is a single unique way to mix three primary lights to produce the color of an arbitrary target light.

What if we have more than three primary lights?
We would end up with an *under-determined* system (e.g., three equations but four unknowns if given four primary lights), which means there are infinitely many ways to mix the primaries to produce the target color.
If we have only two primaries, we end up with an *over-determined* system, where there is in general no solution.

<!-- % https://scholar.harvard.edu/files/schwartz/files/lecture17-color.pdf; something to point students to? -->

### Color Matching Experiments and Color Matching Functions {#sec-chpt-hvs-color-cme-cmf}

@eq-cme gives a mathematical explanation for trichromatic color matching, but it requires knowing the cone fundamentals, which, as we have seen before in @sec-chpt-hvs-receptor-absorb, were not experimentally measured until the mid 20^th^ century, first through microspectrophotometry [@marks1964visual; @brown1964visual; @dartnall1983human] and then through suction electrode [@schnapf1987spectral].
But even without the cone fundamentals, nothing prevents us from performing an actual experiment to find the amount of primaries for producing a color.
Thomas Young apparently had no interest in such an experiment [@mollon2003introduction].
@maxwell1857xviii is believed to be the first to undertake an actual color matching experiment in the 19^th^ century, but he did the experiments using rotating discs painted with different colors, relying on the temporal integration of the HVS.

Modern color matching experiments started with Wright and Guild [@wright1928trichromatic; @wright1929re; @wright1930re; @guild1931colorimetric].
International Commission on Illumination (CIE) in 1931 standardized the color matching experiment and synthesized Wright's and Guild's data (without any additional experiments) to obtain what is now known as the CIE 1931 RGB Color Matching Functions.
This process is discussed in detail in [@broadbent2004critical; @broadbent2008calculation; @service2016the; @zhu2020how].
We summarize the key elements here; the experimental setup is illustrated in @fig-cme_setup.

![Color matching experiment setup. In CIE 1931 standardization of the experiment, the primary lights are spectral lights at 435.8 nm, 546.1 nm, and 700 nm, and they swept the visible spectrum [380 nm, 780 nm] at a 5-nm interval as the target light. Note that CIE 1931 did not do any actual experiments; they synthesized the data from Wright and Guild.](figs/cme_setup){#fig-cme_setup width="100%"}

Observers are presented with a 2$^{\circ}$ visual field.
They are given three primary lights, which in the CIE 1931 standard are **spectral lights** (lights that have photons at only one single wavelength; also called monochromatic lights) at wavelengths 435.8 nm, 546.1 nm, and 700 nm.
The three primary lights are pointed at the same point on one side of the visual field.
On the other side of the visual field is the target light.
Their goal is to adjust the power of each of the three primary lights so that the colors from the two sides of the visual field match.
CIE 1931 swept the entire visible spectrum for the target light at a 5-nm interval.

#### Color Matching Functions Require a Unit System and a White Point

The results obtained through the color matching experiments are shown in @fig-cie1931_rgb_cmf (left panel).
The three curves are collectively called the CIE 1931 RGB **Color Matching Functions** (CMFs).
Intuitively, the CMFs tell us the amount of primaries needed to match the color at each wavelength.
But the devil is in the details.
Let's carefully walk through what this plot actually shows.

![Left: CIE 1931 RGB Color Matching Functions (CMFs); from @cie1931rgbcmf. The $y$-axis shows the number of units needed of each primary so that the mixture matches the color at each wavelength ($x$-axis) on an equal-energy basis. The unit system is so defined that mixing equal amounts (the number of units) of the three primaries produces the color of the equal-energy white, whose SPD is constant over the entire spectrum. Right: the negative values in the CMFs indicate that the corresponding primary light is to be mixed with the target light in order to match the color of the mixture of the other primaries.](figs/cie1931_rgb_cmf){#fig-cie1931_rgb_cmf width="100%"}

The $y$-axis represents the number of units required of each primary so that the mixture matches the color at a given wavelength at $x$-axis.
What is a unit?
The unit system is so defined that mixing the three primaries in equal units produces the color of the Equal-Energy White (EEW), whose SPD is a constant across the spectrum.

There are two judgment calls here.
First, CIE 1931 decided that EEW was going to be the "white" color in their RGB color space.
In general, however, there is no single color that we universally define as white, so if you were to design a color space you get to pick whatever color that you think is white in the color space.
That said, an intuitive choice of white is one that is **achromatic** (colorless), a color that, subjectively, can only be described as having a certain level of gray but that has no apparent hue.
Daylights at different times of a day are perceptually achromatic and could be used as the white point in a color space.
The daylight colors are shown to be very similar to the colors of black-body radiation at different temperatures [@judd1964spectral], shown in @fig-blackbody_colors.

![Color from black-body radiation at different temperatures ($x$-axis; unit: Kelvin). CIE Standard Illuminant D65 approximates the SPD of a noon daylight; its color is similar to that of a 6500 K black-body radiation. From @blackbodyct.](figs/blackbody_colors){#fig-blackbody_colors width="80%"}

You probably do not perceive most of the colors in @fig-blackbody_colors as achromatic on the display right now, but when you are in an environment illuminated by one of these colors, e.g., outdoors at noon, you do perceive the illuminant as achromatic; this is because of **chromatic adaptation**, a topic we will discuss later in @sec-chpt-hvs-adaptations-chroma.
Briefly, the human visual system is evolved to adapt to different daylight colors so that when you spend enough time under such an illuminant, you will see the illuminant as achromatic.
The adaptation to other colors, however, is weak (or "incomplete" in chromatic adaptation parlance) ^[After all, artificial lights are a very recent thing in the scale of evolution, so our HVS has not had a chance to adapt to non-daylight colors yet, if ever.], so it probably does not make much sense to pick other colors as the white point if you want your user to see your white as achromatic.
CIE has standardized a set of what they call Standard Illuminants (D series), each of which approximates a different daylight color.
For instance, the D65 standard illuminant approximates noon daylight and is similar to the color of a black-body radiation at a temperature of 6500 K.
Many common color spaces, such as the sRGB color space, use D65 as the white point.

Second, CIE 1931 RGB space, and virtually all color spaces, define units so that white, however defined, must be produced by an equal-unit mixture of the primaries.
This, again, is a judgment call.
One could totally design a color space where white is produced by mixing, say, 2 units of red and 1 unit of green and blue each --- nothing wrong with that.
It is just more intuitive for most people that white is produced by equal amounts of the primaries.

The $x$-axis in @fig-cie1931_rgb_cmf is defined on an equal-energy/power basis.
That is, the CMFs are interpreted as showing the amount (units) of the primaries needed to produce spectral lights of equal power.
So if we actually mix the three primaries at each wavelength as indicated by the CMFs, we will get a set of spectral lights that have the same power.

#### What Does a Negative Unit Mean?

If you observe @fig-cie1931_rgb_cmf carefully, you will see that some CMFs are negative over certain ranges.
For instance, the red CMF is negative at 500 nm.
This is perhaps a bit surprising, but mathematically it is entirely possible that some values in $[r, g, b]^T$ are negative when solving @eq-cme.
Physically, however, what does it mean to have a negative amount/power of primary light?
The right panel in @fig-cie1931_rgb_cmf provides the intuition.
It turns out that it is impossible to find a combination of the three primary lights to match the color of a spectral light at 500 nm.
What does provide a match is to add a little red primary to the target light, and then we can find a combination of the primaries such as the blue and green mixture has the same color as the target light and red primary mixture.

In fact, if you examine the CMFs, you will see that there is a negative contribution from a primary at all but three wavelengths --- the only three exceptions are the wavelengths of the three primaries (where two of the primary contributions are zero and the other is positive).
This means that no spectral light color (except the three special cases) can be physically produced by mixing the three primaries.

#### Representing Colors Using CMFs

Given a set of CMFs, we can describe the color of a light with a SPD $\Phi(\lambda)$ using the following equation:

$$
\begin{align}
\begin{bmatrix}
\bar{r}(380), \bar{r}(381), \cdots, \bar{r}(780)\\
\bar{g}(380), \bar{g}(381), \cdots, \bar{g}(780)\\
\bar{b}(380), \bar{b}(381), \cdots, \bar{b}(780)
\end{bmatrix}
\times
\begin{bmatrix}
\Phi(380)\\
\Phi(381)\\
\vdots \\
\Phi(780)\\
\end{bmatrix}
=
\begin{bmatrix}
R\\
G\\
B\\
\end{bmatrix}
\end{align}
$$ {#eq-spd2rgb}

\noindent where $\bar{r}(\lambda)$, $\bar{g}(\lambda)$, and $\bar{b}(\lambda)$ are the CMFs, and $R$, $G$, and $B$ are the amounts of the three primaries needed to match the color of $\Phi(\lambda)$.

The CMFs give us another color space, where the color of a light is interpreted as the amount of primary lights needed to match the color of the light.
Of course, if we choose a different set of primary lights, we might end up with a new set of CMFs and a new RGB color space.

### Connecting CMFs and Cone Fundamentals {#sec-chpt-hvs-color-cme-cmf}

CMFs and cone fundamentals both yield trichromatic color vision, so they must be inherently related, as they are just different ways of describing the same thing.
We show the two are linearly related in theory, and the measurement data of the two match well, too.

#### Deriving Color Matching Functions From Cone Fundamentals

Given the cone fundamentals, we can derive the CMFs based on the linear system shown in @eq-cme.
The interactive tutorial by @zhu2022cone2cmf walks through the process, which you are invited to go over, and we will describe the main steps here.

In order to construct the CMFs, we have to match the colors of all the spectral lights, which means we have to specify cone-response matching at each wavelength.
Using the basic idea of @eq-cme, we have:

$$
\begin{align}
\begin{bmatrix}
\sum R(\lambda)L(\lambda),~ \sum G(\lambda)L(\lambda),~ \sum B(\lambda)L(\lambda)\\
\sum R(\lambda)M(\lambda),~ \sum G(\lambda)M(\lambda),~ \sum B(\lambda)M(\lambda)\\
\sum R(\lambda)S(\lambda),~ \sum G(\lambda)S(\lambda),~ \sum B(\lambda)S(\lambda)\\
\end{bmatrix}
\times
\begin{bmatrix}
r(380),\cdots,r(780)\\
g(380),\cdots,g(780)\\
b(380),\cdots,b(780)\\
\end{bmatrix}
=
\begin{bmatrix}
L(380),\cdots,L(780)\\
M(380),\cdots,M(780)\\
S(380),\cdots,S(780)\\
\end{bmatrix},
\end{align}
$$

where $L(\lambda)$, $M(\lambda)$, and $S(\lambda)$ are the cone fundamentals; $L(\lambda_0)$ is the L cone response of the spectral light at a particular wavelength $\lambda_0$;
$[r(\lambda_0), g(\lambda_0), b(\lambda_0)]^T$ represents the (to-be-solved-for) power of each primary needed to match the color of the spectral light at $\lambda_0$;
$R(\lambda)$, $G(\lambda)$, and $B(\lambda)$ are the SPDs of the primary lights used in the CIE 1931 color matching experiment.
The first matrix is a constant matrix given a particular set of CMFs, and we will denote it as the $\mathbf{M}$ matrix.
We can solve the system of equations by inverting the first matrix:

$$
\begin{align}
\begin{bmatrix}
r(380),\cdots,r(780)\\
g(380),\cdots,g(780)\\
b(380),\cdots,b(780)\\
\end{bmatrix}
=
\mathbf{M}^{-1}
\times
\begin{bmatrix}
L(380),\cdots,L(780)\\
M(380),\cdots,M(780)\\
S(380),\cdots,S(780)\\
\end{bmatrix}.
\end{align}
$$

To get the CMFs, however, we need to turn the power measure into a unit measure.
Recall the requirement that white must be produced by equal units of the primaries.
We calculate the power of each primary needed to produce the EEW;
let's denote the solution $[r_w, g_w, b_w]^T$:

$$
\begin{align}
\begin{bmatrix}
r_{w}\\
g_{w}\\
b_{w}\\
\end{bmatrix}
=
\mathbf{M}^{-1}
\times
\begin{bmatrix}
L_{w}\\
M_{w}\\
S_{w}\\
\end{bmatrix},
\end{align}
$$

where $[L_w, M_w, S_w]^T$ denotes the total L, M, and S cone responses of EEW.
For the so-calculated $[r_w, g_w, b_w]$ to represent equal units, the last step is to scale $[\bar{r}(\lambda), \bar{g}(\lambda), \bar{b}(\lambda)]^T$ at each $\lambda$ by $[r_w, g_w, b_w]$:

$$
\begin{align}
\begin{bmatrix}
\bar{r}(380), \cdots, \bar{r}(780)\\
\bar{g}(380), \cdots, \bar{g}(780)\\
\bar{b}(380), \cdots, \bar{b}(780)
\end{bmatrix}
&=
\begin{bmatrix}
r_w,~0,~0\\
0,~g_w,~0\\
0,~0,~b_w
\end{bmatrix}
\times
\begin{bmatrix}
r(380),\cdots,r(780)\\
g(380),\cdots,g(780)\\
b(380),\cdots,b(780)\\
\end{bmatrix}\\
&=
\begin{bmatrix}
r_w,~0,~0\\
0,~g_w,~0\\
0,~0,~b_w
\end{bmatrix}
\times
\mathbf{M}^{-1}
\times
\begin{bmatrix}
L(380),\cdots,L(780)\\
M(380),\cdots,M(780)\\
S(380),\cdots,S(780)\\
\end{bmatrix}\\
&=
\mathbf{T}_{lms2rgb}
\times
\begin{bmatrix}
L(380),\cdots,L(780)\\
M(380),\cdots,M(780)\\
S(380),\cdots,S(780)\\
\end{bmatrix}, \label{eq:cone2cmfsub}
\end{align}
$$ {#eq-cone2cmf}

where $[\bar{r}(\lambda), \bar{g}(\lambda), \bar{b}(\lambda)]^T$ gives us the unit measure, i.e., the values of the CMFs, at each $\lambda$.

#### Cone Space and RGB Space are Related by a Linear Transformation

The rightmost matrix in @eq-cone2cmf is the cone fundamentals written out in the matrix form, and the leftmost matrix in @eq-cone2cmf is the CMFs written out at discrete wavelengths.
So @eq-cone2cmf essentially describes a linear transformation from the cone fundamentals to the RGB CMFs, where the transformation is dictated by $\mathbf{T}_{lms2rgb}$.
We can look at this in two ways.
One, we can think of the cone fundamentals as the CMFs in the cone space: they tell us how much of each cone response we need to match the color of a spectral light.
Two, just like how we can construct the spectral locus from cone fundamentals, the RGB CMFs also give us a way to construct the spectral locus --- in the RGB space.
$\mathbf{T}_{lms2rgb}$ essentially transforms these two representations of the spectral locus, and this is visualized in @fig-cs_linear_transformations.

![The spectral locus in the LMS cone space, CIE 1931 RGB space, and CIE 1931 XYZ space. The color spaces are a linear transformation away from each other. From the interactive tutorials in @zhu2022cone2cmf and @zhu2022xyz.](figs/cs_linear_transformations){#fig-cs_linear_transformations width="100%"}

There is something deeper: $\mathbf{T}_{lms2rgb}$ not only transforms the spectral locus, it transforms the entire coordinate system from the cone space to the RGB space.
In other words, it transforms every single color in the LMS space to its corresponding coordinates in the CIE 1931 RGB space.
The way to think about this is to ask: given that the cone space and the CIE 1931 RGB space provide two ways to represent the color of a light $\Phi$, how are the cone-space representation $[L_c, M_c, S_c]$ and the RGB-space representation $[R_c, G_c, B_c]$ related?
Using @eq-spd2cones, @eq-spd2rgb, and @eq-cone2cmf, it is easy to see that they are related by a linear transformation through $\mathbf{T}_{lms2rgb}$:

$$
\begin{align}
\begin{bmatrix}
R_c\\
G_c\\
B_c
\end{bmatrix}
=
\mathbf{T}_{lms2rgb}
\times
\begin{bmatrix}
L_c\\
M_c\\
S_c
\end{bmatrix}.
\end{align}
$$

#### Cone Responses Fully Explain Psychophysical Color Matching

The CMFs can be both experimentally measured and calculated if we know the cone fundamentals (through a linear transformation), but do the mathematical estimation and the measurement data match?
If so, we can say that the physiological process of encoding light power as cone responses can fully account for the color matching experiments in psychophysics.

@baylor1987spectral performed one such comparison and showed the two sets of data matched very well.
The results are shown in @fig-cmf_coneresponses_match, where the smooth curves are from @stiles1955interim, which uses a different set of primaries and white point than those used in the CIE 1931 RGB CMFs.
The markers are the predicted CMFs through a linear regression from the cone fundamentals measured from macaques, after accounting for ocular and macular absorptions ^[One subtlety is that @baylor1987spectral used suction electrode to measure electrical responses (@sec-chpt-hvs-receptor-suction), so they obtained only the relative absorbance not the absolute absorption of the pigments. So what they actually ended up doing is to use the psychophysical CMFs to fit the peak axial absorption and calculate the cone fundamentals, and show that the regressed CMFs from the so-obtained cone fundamentals match that from psychophysics.].

![Smooth curves are the CMFs from \citet{stiles1955interim}, which uses a different set of primaries and white point than those used in the CIE 1931 RGB CMFs. The markers are the predicted CMFs based on the cone fundamentals measured from macaques. From @baylor1987spectral[Fig. 4A].](figs/cmf_coneresponses_match){#fig-cmf_coneresponses_match width="60%"}

In fact, the modern versions of the cone fundamentals are constructed so that they are precisely a linear transformation away from some RGB CMFs.
For instance, the CIE 2006 "physiologically-relevant" LMS functions (based on @stockman1999spectral and @stockman2000spectral) are constructed by 1) first experimentally measuring the cone fundamentals in psychophysics (from color-vision deficient observers), 2) calibrating the results with a set of RGB CMFs in @stiles1959npl (which uses a different set of primary lights from the CIE 1931 RGB CMFs) to derive a best-fit linear transformation, and 3) applying the linear transformation to the CMFs to derive a "clean" set of cone fundamentals.

## Post-Receptoral Color Encoding: Opponent Processes {#sec-chpt-hvs-color-oppo}

Cone-response encoding can perfectly explain the trichromatic theory of color vision, where any color can be mixed from three other colors.
The trichromatic theory of color has a perfect neural basis: the human visual system has three classes of cones, so color is a three-dimensional system.
But the trichromatic theory is not concerned with our subjective experience of color that we encounter on a daily basis.
Here are two examples that highlight the difference between perceptual color experience and physical color mixing.

First, when we see an orange color, we feel that it has a little bit of yellow in it and a little bit of red in it.
Even though there are many ways to produce orange, some of which do not require mixing yellow and red lights, we cannot help but perceptually feel that orange combines yellow and red.
Second, when we mix a red light with a green light, we get yellow, but perceptually, if we stare at yellow, most people would not say that yellow has contributions from red or green.

@hering1878lehre ^[see translation in @hering1964outlines] hypothesized that, perceptually, there are four primary hues, which form two opposing pairs.
Opposing hues cannot co-exist, perceptually, in a color.
Any hue can be produced by combining two non-opposing hues.
The four hues are: the Yellow and Blue opposing hues and the Red and Green opposing hues.
Hering also considered light-dark as another opposing pair: no color can be simultaneously light and dark.
In his theory, color vision is still a three-dimensional system, where the three axes are: Yellow-Blue axis, Red-Green axis, and light-dark axis.
Any color, a point in this 3D space, is produced by mixing some amount of Red *or* Green, some amount of Yellow *or* Blue, and some level of lightness.

The opponent theory seems to contradict the trichromatic theory, which was dominant for the most part of the history --- because it has both a solid psychophysical and neural basis.
First, the color matching experiment quantitatively shows that, behaviorally, humans could match a color by mixing three other colors.
In contrast, Hering had only a qualitative description of perceptual mixing.
His description was something like "*after this blue comes blue of increasing redness...(blue violet, red violet, purple red), until the last trace of blueness vanishes in a true red.*" [@hering1964outlines, p. 41].
To Hering's theory's rescue, Jameson and Hurvish performed a now-famous experiment, called the **hue cancellation experiment**, providing the first quantitative, psychophysical evidence of the opponent processes [@jameson1955some; @hurvich1957opponent].

Second, the trichromatic theory has a clear neural and physiological basis (i.e., wavelength encoding by cone responses), and the physiological data match the behavioral data very well, as shown before.
So a natural question is: are there neural mechanisms that can account for the opponent processes and, if so, how does that mechanism relate to the encoding mechanisms by the cone photoreceptors?

It turns out that we do need a set of new neural mechanisms to start accounting for the opponent processes.
Not only do these new mechanisms *not* contradict the cone encoding mechanisms, they build on top of the cone encodings and operate post-receptorally.
@schrodinger1925verhaltnis ^[see translation in @schrodinger1994relationship] synthesized the earlier *zone theory* by @kries1905ubersicht and argued that the trichromatic theory and the opponent processes were nothing more than different stages of color encoding in the visual system.
That said, while these new neural mechanisms seem to have what it takes to form the basis for the behavioral opponent observations, they do not fully explain those observations yet; the link between the two is still very much an open research question.

The rest of this section will discuss the hue cancellation experiment and the quest for a neural and physiological basis in more detail.

### Hue Cancellation Experiment {#sec-chpt-hvs-color-oppo-hue}

In a landmark study, @jameson1955some (while working for Eastman Kodak in Rochester) quantitatively measured the perceptual color opponency using a behavioral experiment.
The participant is given a test light and is asked to first judge whether the light appeared blue-ish or yellow-ish.
If the test light is judged to be blue-ish, the participant is then given a yellow-ish *cancellation light* (e.g., a spectral light at 588 nm) and is asked to adjust the intensity of the cancellation light so that the mixture of the test and cancellation light perceptually appears neither blue nor yellow.
If the test light is judged to be yellow-ish, the participant is then asked to adjust the power of a blue-ish cancellation light (e.g., a spectral light at 467 nm) so that the test-cancellation mixture is again neither blue nor yellow.
We sweep the spectrum from about 400 nm to 700 nm for the test light of equal energy, and record the energy of yellow or blue cancellation light needed at each step.

![Measurements from the hue cancellation experiment in @jameson1955some. (a) the Blue-Yellow measurement; the $y$-axis shows the intensity of the Yellow/Blue cancellation light, i.e., the relative strength of the "Blue-ness" and "Yellow-ness" in the test light. (b) the Red-Green measurement; notice the two zero-crossings for Green. (c) The same data as A and B except we invert the Blue and Green curves so the $y$-axis is interpreted as the strength of Red-ness and Yellow-ness.](figs/hue_cancellation_experiment_new){#fig-hue_cancellation_experiment width="100%"}

The result for one subject is shown in @fig-hue_cancellation_experiment (a), where the $y$-axis is showing the intensity of the yellow and blue cancellation light, i.e., the strength of blue-ness and yellow-ness of the test light.
For the reference, we attached a colorbar showing roughly the color of the test light between 400 nm and 700 nm, but take this color visualization as a huge grain of salt, since it is almost certain that your display will not be able to actually render the colors of the spectral lights.

Unsurprisingly, we get two peaks, one in the blue range and the other in the yellow range, indicating, respectively, that the participant needs a lot of the yellow and blue cancellation lights in those two regions.
The test light at about 500 nm requires no cancellation light, indicating light there, which roughly has a green-ish color is yellow-blue neutral: it naturally looks neither blue nor yellow.

Jameson and Hurvich then repeated the same experiment, but this time measuring the red-green opponent process, where the two cancellation lights are a 700 nm red-ish light and a 490 nm green-ish light.
The results are in @fig-hue_cancellation_experiment (b), where the $y$-axis indicates the amount of red-ness and green-ness in the test light.
Two observations are worth noting.
First, while it is unsurprising that long-wavelength lights have a strong red component, it is perhaps surprising that short-wavelength lights appear red-ish too.
That, however, becomes less surprising when we realize that short-wavelength lights (shorter than pure blue) appear violet, which perceptually is a red-ish blue.
Second, because of the two red-ish regions over the spectrum, the entire red-green curve has two zero-crossings, one at about 470 nm and the other near 570 nm: pure blue and pure yellow look neither green nor red.

@fig-hue_cancellation_experiment (c) summarizes the two sets of data by inverting the blur section of the curve in (a) and the green section of the curve in (b).
That way, the $y$-axis can be simply interpreted as the relative strength of red-ness and yellow-ness over the spectrum.

### Light-Dark Mechanism and Luminous Efficiency Function {#sec-chpt-hvs-color-oppo-light}

@hurvich1957opponent also performed a measurement of the white-black (light-dark) opponent process, asking participants to assess the "whiteness" of spectral lights between 400 nm and 700 nm of equal power.
%Intuitively, the measurement tells us the perceived brightness of lights at different wavelengths.
A more modern method to measure the luminance mechanism is heterochromatic flicker photometry, where we alternate between a test light and a fixed reference light at a frequency of, say, 25 Hz.
We adjust the intensity of the test light so that the alternation produces no visual flickering, at which point we say the two lights produce the same level of luminance [@sharpe2005luminous; @sharpe2011luminous].
We again sweep the entire visible spectrum for the test light and record the relative intensity at each step.
The so-obtained function is called the **luminance efficiency function** (LEF).
The dashed gray curve in @fig-lef shows a modern version of the photopic LEF (the so-called CIE 2008 "physiologically-relevant" 2-deg function) ^[In later research by Jameson and Hurvich, their white-black function was made equal to the CIE 1924 luminous efficiency function [@hurvich1955some, p. 604], which is known to have severe flaws at low wavelengths and which is later corrected by @judd1951report and @vos1978colorimetric.
Compared to the Judd and Vos corrections, the function shown here has the advantage of being “physiologically relevant” in that the LEF is a linear combination of the cone fundamentals, whereas both the CIE 1924 LEF and its later corrections are not intentionally designed to be linear combinations of anything.].

![The grey solid curve is the scotopic luminous efficiency function (CIE 1951 standard; based on @wald1945human and @crawford1949scotopic). The grey dashed curve is the photopic luminous efficiency function (CIE 2008 "physiologically-relevant" 2-deg function; based on @sharpe2005luminous and @sharpe2011luminous) The other three curves are the cone fundamentals, shown for the reference.](figs/lef){#fig-lef width="60%"}

The way to interpret the LEF is that the $y$-axis is inversely proportional to the light power at each wavelength needed to produce the same level of perceptual brightness.
The photopic LEF at 509 nm is about 0.5, half of that at 555 nm.
It means we need twice as much power at 509 nm to produce the same level of brightness as that at 555 nm.
It also explains the word "efficiency" in the name: if a wavelength needs less power to produce a criterion level of brightness, the wavelength is more efficient in its use of power.
The way LEF is obtained, however, does *not* permit us to interpret the result as the relative brightness at different wavelengths.
That is, 555 nm is not twice as bright as 509 nm.
This is similar to our interpretation of the cone fundamentals.

For comparison, the gray curve in @fig-lef is the scotopic LEF.
The CIE 1951 scotopic LEF synthesizes the psychophysical measurements from @wald1945human and @crawford1949scotopic.
Both used a threshold method where they measured the light intensity at each wavelength needed to produce a just detectable flash.
Note that the photopic LEF peaks at about 555 nm and the scotopic LEF peaks at about 507 nm.

As a result, the relative brightness of longer-wavelength colors and shorter-wavelength colors is inverted when our vision transitions from the cone-mediated photopic vision to the rod-mediated scotopic vision.
This phenomenon is called the **Purkinje shift**.
In the words of @glassner1995principles[p. 21], "*When the sun is still above the horizon, your cones are active, and the yellow flower will appear lighter than the leaves because yellow is closer to peak of the photopic sensitivity curve than dark green. When the sun has set and light levels are lower, your rods are the principal sensors. The scotopic sensitivity curve is more responsive in the shorter wavelengths, so the green leaves will now appear relatively lighter than the yellow flower, though both will of course be much darker due to the lower amount of incident light.*"

![The solid curve is the white-black measurement, indicating the amount of whiteness in a light across the spectrum. The white-black curve in theory matches the luminous efficiency function. The two plots are for two participants. From @hurvich1957opponent[Fig. 4].](figs/hue_cancellation_experiment_white){#fig-hue_cancellation_experiment_white width="100%"}

Combining the light-dark (luminance efficiency) curve with the two opponent curves in @fig-hue_cancellation_experiment (c), we again have three spectral sensitivity functions.
@fig-hue_cancellation_experiment_white puts the three opponent measurements in one plot (the two plots are for two separate participants).
Compare this plot with the cone fundamentals in @fig-normalized_cone_fundamentals.
Once again, a light with its SPD can be reduce to three-dimensional point, using @eq-spd2cones_int, except 1) instead of the three cone fundamentals we use the three opponent functions and 2) instead of getting the three cone responses we get the strength of the three opponent mechanisms.
Effectively, the hue cancellation curves and the light-dark curve construct a new three-dimensional color space.
We call this the **hue-opponent** space, and we will return to this space in @sec-chpt-hvs-color-oppobasis-model and discuss how this space relates to the colorimetric spaces we have discussed so far.

## Neural and Physiological Basis of Opponent Processes {#sec-chpt-hvs-color-oppobasis}

The hue cancellation experiment solidifies Hering's opponent theory at the level of psychophysics.
But recall @fig-abstractions; any behavioral responses measured through psychophysics are fundamentally the result of the underlying neural and physiological mechanisms.
So the next natural step in the scientific quest is to understand what underlying neural and physiological mechanisms can account for the behavioral opponent processes.

![Responses of six typical classes of LGN neurons to incremental flashes of varying wavelengths. $y$-axis shows the spikes/second under spectral lights of equal energy. Each curve represents a particular energy level. (A): these cells are excited (activity exceeds the spontaneous firing rate) by red hues and inhibited by green hues, denoted +R-G cells. (B): +G-R cells. (C): +B-Y cells. (D): +Y-B cells. (E): non-opponent excitatory cell. (F): non-opponent inhibitory cell. From @devalois1990spatial[Fig. 7.5], which is adapted from @de1966analysis[Fig. 9--12, 15--16].](figs/opponent_lgn_cells){#fig-opponent_lgn_cells width="100%"}

### Spectrally-Opponent and Non-Opponent Neurons {#sec-chpt-hvs-color-oppobasis:neurons}

There are RGC and LGN neurons that show opponent properties.
@svaetichin1953cone, @svaetichin1956spectral, and @svaetichin1958retinal are the first to identify opponent neurons in a fish retina; they recorded from horizontal cells.
@de1958response and @de1966analysis measured the responses of LGN neurons in macaques using monochromatic lights, and found spectral opponent neurons, which get excited or inhibited depending on the wavelengths.
(A -- D) in @fig-opponent_lgn_cells show the recordings of four classes of opponent cells.
(A) shows a class of LGN cells whose firing rate exceeds the spontaneous rate under long-wavelength, red-ish lights and whose firing rate drops below the spontaneous rate under short-wavelength, blue-is lights.
These cells are denoted +R-G (red-ON/green-OFF) cells.
(B), (C), and (D) show that there exists +G-R, +B-Y, and +Y-B cells, respectively.

@de1966analysis also identified non-opponent cells, whose responses are universally inhibited or excited across the spectrum, as shown in (E) and (F) in @fig-opponent_lgn_cells, respectively.
These neurons are still wavelength-sensitive, but their responses are either universally excited or universally inhibited across the spectrum, unlike the spectrally-opponent neurons whose responses change polarity across the spectrum.

### Potential Neural Circuitries {#sec-chpt-hvs-color-oppobasis-cir}

What are some of the underlying visual pathways that could potentially give rise to these spectral tuning curves?
Recall that LGN cells/RGCs have antagonistic Receptive Fields (RFs), and the antagonism seems to be a perfect mechanism to implement the opponent process.
This suggests that in order to understand the opponent cells we must study their RF structures.

Much of the early work is done by @wiesel1966spatial.
While De Valois and his collaborators used diffuse lights to illuminate a large visual field, @wiesel1966spatial used both small spot lights that stimulated the center of the RF and larger lights that covered the entire RF.
By comparing the responses under these two stimuli across different wavelengths (and white), they suggested potential RF structures of both opponent and non-opponent cells in macaque LGN.
@derrington1984chromatic designed a clever experiment that explicitly tied cone responses to LGN cell responses and thus more directly revealed the RF structure.

Before getting into the details, it is worth reminding ourselves that studying the LGN cells and studying the RGCs are equivalent (@sec-chpt-hvs-percept-postretina-lgn), since different classes of RGCs project to distinct LGN layers with virtually the same RFs: midget RGCs project to the Parvocellular layers (P cells) in the LGN (forming the P pathway/stream), parasol RGCs project to the Magnocellular layers (M cells) in the LGN (forming the M pathway/stream), and bistratetified RGCs project to the Koniocellular layers (K cells) in the LGN (forming the K pathway/stream).

#### Y-B Opponent Cells

The visual pathway for the Y-B opponent cells seems to be clear.
@derrington1984chromatic showed that some LGN cells receive antagonistic inputs from S cone vs. L and M cones.
@dacey1994blue later identified that the small bistratified RGCs (which project to the K cells in the LGN) are responsible for carrying such signals.
The small bistratified RGCs are excited by S cone responses and inhibited by L and M cone responses (or vice versa).
Since blue-ish lights produce strong S cone responses and red/green lights produce strong L/M cone responses (recall red + green is yellow), it stands to reason that if a cell is excited by S cones and inhibited by L and M cones, it would give a vigorous on-response under blue lights and a vigorous off-response under yellow lights, producing the kind of yellow-ON/blue-OFF spectral tuning curve that we see in @fig-opponent_lgn_cells (C).

![The small bistratefied RGCs might be the substrate for the Y-B pathway. (A): illustration of the receptive field structure of a small bistratefied RGC, which is S-on and L/M-off (there are also S-off and L/M-on ones); from @rodieck1998first[p. 348]. (B): a small bistratefied RGC receives excitatory inputs from S cones through the S-cone bipolar cells and inhibitory inputs from L and M cones through another class of bipolar cells; from @rodieck1998first[p. 346]. (C): membrane potential and spike rate of small bistratified cells under periodic, out-of-phase blue-yellow lights; adapted from @dacey1994blue[Fig. 3C].](figs/yb_pathway){#fig-yb_pathway width="100%"}

@fig-yb_pathway (A) illustrates the potential Receptive Field (RF) of a yellow-ON/blue-OFF small bistratefied cell, and (B) shows the neutral circuitry that gives rise to such an RF (but also see @field2007spatial).
The small bistratefied RGC have a center-only RF, which receives excitatory responses from a S-cone bipolar cell and inhibitory responses from another class of bipolar cells that are connected to L and M cones.
@dacey1994blue records both the membrane potential and the spiking rate of a small bistratified RGC, shown in (C), under periodic, out-of-phase blue and yellow (red+green) lights.
The cell's responses are the strongest under maximum yellow light (maximum excitatory S cone responses) and minimum blue lights (minimum inhibitory L and M cone responses).

#### R-G Opponent Cells

@derrington1984chromatic showed that most of the midget RGCs (and thus P cells in LGN) are either excited by L cone responses and inhibited by M cone responses (L-ON/M-OFF) or the other way around.
Given that, loosely, L cones are excited by red-ish lights but not so much by green-ish lights and M cones behave oppositely, it stands to reason that L-ON/M-OFF cells produce vigorous on-responses (above spontaneous rate) under red lights and vigorous off-responses (below spontaneous rate) under green lights, giving a spectral tuning curves shown in @fig-opponent_lgn_cells (A).

The actual RF structure of these cells takes two forms [@wiesel1966spatial].
Some of these cells have a center-surround RF, so there are four combinations: L+/M- (L center-ON/M surround-OFF), L-/M+, M-/L+, and M+/L-.
Other midget RGCs have no center-surround arrangement.
The excitatory and inhibitory regions have the same spatial extent.
Either way, signals from the L cones and M cones are antagonistic in these cells.

#### Non-Opponent Cells

Finally, the parasol RGCs (and thus M cells in LGN) seem to be the most probable source for the luminance opponent mechanism [@lee1988physiological].
These cells do have a center-surround RF but the L cones and M cones contribute to both the center and the surround [@wiesel1966spatial]; S cones seem to be contribute little, if any, to these cells [@lennie1993luminance].
When the total excitation by the L and M cones to the center out-weighs the total inhibition to the surround, the entire cell appears to be excited by L and M cone responses, giving a broadband, non-opponent spectral tuning curve in @fig-opponent_lgn_cells (E); otherwise we see a tuning curve like @fig-opponent_lgn_cells (F).

<!-- See Dowling for this as well. -->

### A Cone-Opponent Model for Color-Opponent Mechanisms {#sec-chpt-hvs-color-oppobasis-model}

It is clear that there are cells that receive opponent cone signals; the spectral tuning curves of these cells seem to largely account for the perceptual opponent mechanisms.
Based on these observations, @derrington1984chromatic proposed a *cone-opponent* color space, which is now commonly used (in color science and, to a large extent, visual neuroscience) to give a first-order approximation of the perceptual color-opponent processes.
The color space is now famously known as the DKL color space ^[named after the three authors; the L is Peter Lennie, who was twice on the faculty at University of Rochester and served as the Provost].

* The Y-B channel is given by $a$S-($b$L+$c$M), where $a$, $b$, and $c$ are all positive values representing the contributions of the S, L, and M cones to the Y-B opponent process.  It is generally said that this signal is delivered by the Koniocellular pathway.
* The R-G channel is given by $d$L-$e$M, where $d$ and $e$ are all positive values representing the contributions of the L and M cones to the R-G opponent process.  This opponent signal is generally said to be delivered by the Parvocellular pathway.
* The Light-Dark or luminance channel is given by $f$L+$g$M, where $f$ and $g$ are all positive values representing the contributions of the L and M cones to the luminance channel.  This luminance channel is meant to represent the LEF (@sec-chpt-hvs-color-oppo-light), which generally is believed to be delivered by the Magnocellular pathway.

The DKL space operates not on raw cone responses but on response *contrasts* with respect to a perceptually neutral/achromatic color.
The inherent assumption is that the achromatic color should have no strength in any of the three cone-opponent channels and be the origin in the cone-opponent space.
The achromatic color depends on an observer's state of chromatic adaptation, a topic we will discuss later in @sec-chpt-hvs-cori-cm-ca.
People usually fit data to regress the values of the free parameters, and the exact values depend on which cone fundamentals are used and the normalization convention.
@brainard1996cone describes one such procedure.

Since the cone-opponent model operates on (contrast of) cone responses, a common theory of color vision is that it is a two-stage process: the wavelength encoding by cone photoreceptors followed by opponent encoding of cone responses post-receptorally.
While the cone response encoding can perfectly explain the color matching experiments as we have see earlier,  the cone opponent encoding is only an approximation of the hue cancellation experiments, as we will see next.

### There are Many Inconvenient Truths {#sec-chpt-hvs-color-oppobasis-truth}

The cone-opponent model is a good approximation for behavioral color-opponent mechanisms, but there are many inconsistencies between these two.
Reconciling the two and thus elucidating how humans perceptually code opponent hues is still an open research question.

#### P and K Pathways Do Not Fully Account For R-G and Y-B Opponent Processes

The opponent neurons clearly have what it takes to start accounting for the perceptual opponent processes, but the spectral tuning curves of those neurons have only a weak correlation with the hue cancellation curves.
Thus, it is unlikely that excitation and inhibition in opponent neurons cause our perception of red-green and blue-yellow opponency.

The most jarring difference appears in the R-G process.
The R-G hue cancellation curve (@fig-hue_cancellation_experiment (C)) shows two perceptually neutral colors, as there are two zero-crossings.
However, the spectral tuning curve of the R-G neurons (@fig-opponent_lgn_cells (A--B)) shows only one zero-crossing.
These neurons do not predict the R-G neutral color in the short-wavelength range and, by extension, cannot explain the fact that short-wavelength violet-ish lights appear to have a red hue.
@derrington1984chromatic (also see @wandell1995foundations[Fig. 9.18]) shows a great deal of variation of the spectral tuning property within P cells, making them even less certain as the sole candidate for R-G opponent mechanism.

In fact, people have shown that the perceptual R-G hue cancellation data can be fit by $a'$L-$b'$M+$c'$S, where $a'$, $b'$, and $c'$ are cone contributions [@poirson1993appearance; @bauml1996color].
Intuitively, the contribution by S cones in the short-wavelength range could give rise to a positive response there.
However, there is no physiological evidence that L cone and S cone responses combine at some point in the visual pathway, suggesting the phenomenological nature of these models.

Even though the K pathway clearly shows the capability of carrying S vs. L+M signals, the latter do not accurately predict Y-B neutral signals and, thus, do not fully account for the Y-B hue opponency.
That is, a color that leads to a null response (no significant increase or decrease compared to the spontaneous response rate) in the L-M channel is not perceptually pure yellow or pure blue [@shevell2017color, Fig. 4f].
Similarly, a color that causes a null response in the S-(L+M) channel is not perceptually pure red or pure green.
That is, null-response colors in the DKL cone-opponent space are not perceptually neutral in the hue-opponent space, implying fundamental discrepancies between cone-opponent and hue-opponent spaces.
<!-- talk about the threshold of detecting chromatic change and that it matches well with the neural curves? -->

#### M Pathway Does Not Fully Account For Luminance

The Magnocellular pathway (starting from the parasol RGCs) is said to be responsible for the dark-light opponent cells, but that poses a dilemma.
We know that parasol RGCs have large RFs.
A large RF is equivalently to applying an aggressive low-pass filter to the optical image; as a result, the M pathway has a low spatial acuity.
So if the M pathway is fully responsible for mediating our luminance perception, we should be insensitive to spatial blurring (low-pass filtering) in the luminance signal.
But the result is the opposite: our vision is very sensitive to spatial blurring in in the luminance channel (but relatively insensitive to blurring in the two color opponent channels).

![We take an image, decouple it into three channels: luminance, red-green, and blue-yellow. We then spatially blur one of the channels while keeping the other two channels unchanged and then reconstruct the image. Our vision is much more sensitive to spatially blurring in the luminance channel (a) than is to blurring in the red-green channel (b) and in the blue-yellow channel (c). This is the basis of chroma subsampling used in modern image and video compression algorithms. The original image is *The Art of Painting* from Johannes Vermeer @aop. See another example in @wandell1995foundations[Fig. 9.23].](figs/channel_blurring_new){#fig-channel_blurring width="100%"}

This is illustrated in @fig-channel_blurring, where we take an image, decouple it into three channels: luminance, red-green, and blue-yellow.
We then spatially blur one of the channels while keeping the other two channels unchanged and then reconstruct the image.
Our vision is much more sensitive to spatially blurring in the luminance channel (a) than is to blurring in the red-green channel (b) and in the blue-yellow channel (c); in fact, this is the basis of **chroma subsampling**, a key step in modern image and video compression algorithms.
This suggests that the M pathway alone cannot be exclusively responsible for our luminance perception.

@gouras1979enhancement also shows that P cells, which are ordinarily thought of as L-M spectrally-opponent, could also give a LEF-like spectral tuning curve as if it acts as the luminance channel.
The reason is that the surround signals reach a cell later than do the center signals, so at a high frequency the out-of-phase center-surround signals can actually come in the same phase.

#### Hue-Opponent Space is Not a Linear Transformation from Cone Space

It is perhaps not surprising, by now, that if there is a color space that can fully account for the perceptual coding of opponent hues, it is never going to be a linear transformation from the LMS space (or any other space that is a linear transformation away from the LMS space, e.g., the CIE 1931 XYZ space or the DKL cone-opponent space).

As we have seen above, for instance, the DKL space [@derrington1984chromatic], which is a linear transformation from the LMS cone space, does not fully account for the perceptual opponent processes, e.g., does not predict any unique hue.
People have shown that one can construct a linear transformation from the LMS space that can accurately predict three of the four unique perceptual hues by fitting data from psychophysical measurements that do not presuppose the existence of opponent mechanisms [@poirson1993appearance; @bauml1996color], but they cannot predict the fourth unique hue.
@schrodinger1925verhaltnis also estimated a linear transformation between the cone response space and the hue-opponent space based on the four unique hues, but the transformation could not accurately predict the achromatic color (also see the commentary by Zaidi in @schrodinger1994relationship).

The reason is that perceptually unique red and green hues are not *collinear* with white, the achromatic color that is perceptually neutral in both the Y-B and R-G channel, i.e., does not appear yellow, blue, red, nor green ^[Again, what is considered achromatic depends on the observer's adaptation state; there is no single achromatic color.].
That is, red, white, and green do not lie on a line.
Why is this significant?
Assuming there was a linear transformation $T$ from the cone responses to the strengths of the hue-opponent mechanisms:

\begin{align}
\begin{bmatrix}
\text{Y/B}\\
\text{R/G}\\
\text{Lum}
\end{bmatrix}
=
T
\times
\begin{bmatrix}
L\\
M\\
S
\end{bmatrix}
\end{align}

Both unique red hue ($[L_R, M_R, S_R]$) and unique green hue ($[L_G, M_G, S_G]$) have no yellow (or blue) hue, so their response in the Y-B channel response would be 0:

\begin{align}
\begin{bmatrix}
\text{0}\\
|\\
|
\end{bmatrix}
=
T
\times
\begin{bmatrix}
L_R\\
M_R\\
S_R
\end{bmatrix},~~~
\begin{bmatrix}
\text{0}\\
|\\
|
\end{bmatrix}
=
T
\times
\begin{bmatrix}
L_G\\
M_G\\
S_G
\end{bmatrix}
\end{align}

Therefore, any mixture of the unique red hue and the unique green hue would not appear to have a yellow hue either:

\begin{align}
\begin{bmatrix}
\text{0}\\
|\\
|
\end{bmatrix}
=
T
\times
\begin{bmatrix}
a L_R + b L_G\\
a M_R + b M_G\\
a S_R + b S_G
\end{bmatrix},
\end{align}

where $a$ and $b$ are contributions of red and green to the mixed color.
However, we know that when we mix red with green colors we get yellow.
The fact that two colors without any yellow hue can generate a color that does have a yellow hue means the hue-opponent space cannot be a linear transformation from the LMS cone space.

![Circles are unique hues derived from psychophysics reported in @bauml1993ratio. Fitting lines and extrapolating the lines give us estimations of unique hues that are spectral colors. Three of the four unique spectral hues (blue at 474 nm, green at 506 nm, and yellow at 568 nm) can be accurately predicted by a linear transformation constructed by @bauml1996color, but not the unique red hue. The fact that the red, white, and green are not collinear suggests that there is no linear transformation between the hue-opponent space and the cone space. Adapted from @bauml1996color[Fig. 12].](figs/unique_hues){#fig-unique_hues width="80%"}

@fig-unique_hues illustrates this point with some real data.
The empty markers are three sets of perceptually unique hues (which do not have to be spectral colors) measured psychophysically in @bauml1993ratio.
When we fit a straight line across each set of unique hues and extrapolate the line we can estimate what spectral colors are unique hues (blue Ⓑ, green Ⓖ, and yellow Ⓨ).
No spectral color is seen as a unique red hue (all spectral red-ish colors appear to have a yellow hue), which requires a mixture of unique blue hue and a spectral red to cancel the yellow percept [@dimmick1939spectralyellow; @larimer1975opponent] (and also see the commentary by Zaidi in @schrodinger1994relationship).
@dimmick1939spectralred measured that unique red hues Ⓡ are complementary to a spectral light at 494 nm; that is, spectral light at 494 nm, white Ⓦ, and unique red hues should fall on a straight line ^[Of course, it is conceivable the result might vary in population and depend on the adaptation state (i.e., what is considered white/achromatic).].

@bauml1996color constructed a linear transformation from the cone space to the hue-opponent space that can accurately predict the unique spectral hues of blue, green, and yellow.
It is comforting, and corroborates others [@larimer1974opponent], that blue Ⓑ, white Ⓦ, and yellow Ⓨ are collinear, as would be required by a linear transformation from the cone space to the hue-opponent space: mixing colors that have no green or red hue will not give a color that does.
But clearly the predicted red hue Ⓡ' deviates significantly away from red hue Ⓡ from actual measurements.
If we connect the unique green hue Ⓖ and unique red hue Ⓡ, the line would not across Ⓦ.
This suggests that a simple linear transformation does not exist; at least the Y-B null-response axis is not linear with respect to the cone responses.
Non-linear models have been proposed [@larimer1975opponent; @shevell2017color].

<!-- so maybe an explanation is that the actual transformation, which has to be non-linear, coincides with the linear transformation at hues that do match, but not at others. just imagine two transformations, Tlinear and Tnon; both can transform YBGR correctly from LMS space to the opponent space, but in Tlinear the points along the RG line are not correctly transformed but they are in Tnon. Maybe Tnon is a piece-wise linear transformation? see also \citet[p. 257]{kaiser1996human}; related? -->